{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CLIPProcessor, CLIPTextModel, CLIPTokenizer, CLIPVisionModel,CLIPModel,CLIPConfig\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
    "model = CLIPModel.from_pretrained(\n",
    "    \"output_model/epoch_1\", torch_dtype=torch.float16\n",
    ").to(device)\n",
    "# 使用pretrained\n",
    "# model = CLIPModel.from_pretrained(\n",
    "#     base_model, torch_dtype=torch.float16\n",
    "# ).to(device) \n",
    "processor = CLIPProcessor.from_pretrained(\n",
    "    base_model, torch_dtype=torch.float16\n",
    ")\n",
    "model.eval()\n",
    "model_vision = model.vision_model\n",
    "visual_projection = model.visual_projection\n",
    "model_text = model.text_model\n",
    "text_projection = model.text_projection\n",
    "\n",
    "cos = torch.nn.CosineSimilarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "path =\"topic2_release/test\"\n",
    "animal_type = os.listdir(path)\n",
    "animal_type.sort()\n",
    "animal_type_prefix = [f\"a photo of {animal}\" for animal in animal_type]\n",
    "images_test = []\n",
    "images_pil_list = []\n",
    "for i in tqdm(range(len(animal_type))):\n",
    "    animal = animal_type[i]\n",
    "    image_list = os.listdir(f\"{path}/{animal}\")\n",
    "    image_list.sort()\n",
    "    images = [Image.open(f\"{path}/{animal}/{file}\") for file in image_list]\n",
    "    images_pil_list.extend(images)\n",
    "    inputs = processor(\n",
    "        text=animal_type_prefix,\n",
    "        images=images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "    # 節省VRAM，每十張inference一次\n",
    "    for i in range(0,inputs[\"pixel_values\"].shape[0],10):\n",
    "        pixel_values = inputs[\"pixel_values\"][i:i+10].to(device)\n",
    "        images = model_vision(pixel_values=pixel_values)\n",
    "        images_test.append(visual_projection(images.pooler_output).cpu().detach())\n",
    "database = torch.cat(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk=10: [1.0, 0.99778, 0.99, 0.99111, 1.0, 0.99889, 1.0, 0.99778, 0.99, 1.0] avg: 0.99656\n",
      "topk=20: [0.99947, 0.99789, 0.99053, 0.99263, 1.0, 0.99947, 1.0, 0.99842, 0.99, 0.99947] avg: 0.99679\n",
      "topk=50: [0.99122, 0.99755, 0.99143, 0.99327, 0.9998, 0.99878, 1.0, 0.99898, 0.99, 0.99959] avg: 0.99606\n",
      "topk=100: [0.97939, 0.98545, 0.98283, 0.98242, 0.9896, 0.95626, 0.99303, 0.97061, 0.97596, 0.99798] avg: 0.98135\n"
     ]
    }
   ],
   "source": [
    "top_k = [10, 20, 50, 100]\n",
    "precision_list = []\n",
    "for top_num in top_k:\n",
    "    for i in range(0, 1000, 100):\n",
    "        precision = []\n",
    "        for j in range(0, 100):\n",
    "            target = database[i + j]\n",
    "            retrieved = cos(target.unsqueeze(0), database).topk(top_num)\n",
    "            true_num = torch.logical_and(\n",
    "                retrieved.indices >= i, retrieved.indices < i + 100\n",
    "            ).sum()\n",
    "            precision.append(((true_num - 1) / (top_num - 1)).item())\n",
    "        precision_list.append(round(sum(precision) / 100, 5))\n",
    "for i in range(len(top_k)):\n",
    "    print(\n",
    "        f\"topk={top_k[i]}: {precision_list[i*10:i*10+10]} avg: {round(sum(precision_list[i*10:i*10+10])/10,5)}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
